{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wiktor Dyngosz Module 5 - training.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "e5oyiOADtpDA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Environment preparation - fetching dataset and library import"
      ]
    },
    {
      "metadata": {
        "id": "wflsY2wvtZ1h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "from scipy import misc\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cz2JJbMRHmKV",
        "colab_type": "code",
        "outputId": "ec7abbe4-4a60-4d62-bfca-f37e136e275e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NpwZ8qNbxGw6",
        "colab_type": "code",
        "outputId": "7247f411-dbe9-4142-ccec-2124ac51c51d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "! date && unzip -q /content/drive/'My Drive'/celeb_dataset.zip -d /content/  && date #unzip dataset into local machine"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Dec 18 18:37:12 UTC 2018\n",
            "replace /content/celeb/Anno/list_landmarks_align_celeba.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rJi0ivw_BmGf",
        "colab_type": "code",
        "outputId": "f93925f8-e31a-438e-85ff-4e552bba7213",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "#create a directory for preprocessed TFRecord files\n",
        "!ls /content/\n",
        "!mkdir /content/preprocessed/\n",
        "!ls /content/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "celeb  drive  preprocessed  sample_data\n",
            "mkdir: cannot create directory ‘/content/preprocessed/’: File exists\n",
            "celeb  drive  preprocessed  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RTz-2mYx4fua",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def peek_file(file_path, n_lines):\n",
        "  \"\"\"\n",
        "  helper function to peek first n_lines of the file\n",
        "  \"\"\"\n",
        "  try:\n",
        "    n_lines = int(n_lines)\n",
        "    assert(n_lines > 0)\n",
        "  except ValueError:\n",
        "    print(\"Number of lines argument must be integer-interpretable\")\n",
        "  except AssertionError:\n",
        "    print(\"Number of lines must be positive\")\n",
        "    \n",
        "  with open(file_path) as file:\n",
        "    for line in range(n_lines):\n",
        "      print(file.readline(), end=\"\")\n",
        "  return\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HU0WLUEnxMXM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Settings"
      ]
    },
    {
      "metadata": {
        "id": "Y79GEERuxd6a",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# path to downloaded dataset (unzipped)\n",
        "DOWNLOADED_PATH = '/content/celeb' #@param {type:\"string\"}\n",
        "\n",
        "# path to preprocessed dataset (tf records)\n",
        "SAVED_DATASET = '/content/preprocessed/' #@param {type:\"string\"}\n",
        "\n",
        "TRAIN_FILENAME = 'train.tfrecords' #@param {type:\"string\"}\n",
        "VAL_FILENAME = 'val.tfrecords' #@param {type:\"string\"}\n",
        "TEST_FILENAME = 'test.tfrecords' #@param {type:\"string\"}\n",
        "\n",
        "ANNO_PATH = os.path.join(DOWNLOADED_PATH, 'Anno',  'list_attr_celeba.txt') #file that indicates to which classes an image belongs to \n",
        "IMG_PATH = os.path.join(DOWNLOADED_PATH, 'Img') #path to images directory\n",
        "EVAL_PATH = os.path.join(DOWNLOADED_PATH, 'Eval', 'list_eval_partition.txt') #file that indicates how to split the dataset into training, validation and testing sets\n",
        "\n",
        "# tensorflow tf records dataset settings\n",
        "DECODE_PARALLEL_CALLS = 260 #@param {type:\"slider\", min:20, max:1000, step:1}\n",
        "SHUFFLE_BUFFER_SIZE = 100 #@param {type:\"slider\", min:20, max:1000, step:1}\n",
        "PREFETCH_BUFFER_SIZE = 100 #@param {type:\"slider\", min:20, max:1000, step:1}\n",
        "\n",
        "BATCH_SIZE = 32 #@param {type:\"slider\", min:0, max:1000, step:1}\n",
        "\n",
        "EPOCHS = 3 #@param {type:\"slider\", min:0, max:1000, step:1}\n",
        "\n",
        "\n",
        "COUNT_LIMIT = None #@param {type:\"raw\"}\n",
        "\n",
        "LEARNING_RATE =  0.00001 #@param {type:\"slider\", min: 0.00001, max:1, step: 0.00001}\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h7Ok7Y2G7jyf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Decoding TFRecords"
      ]
    },
    {
      "metadata": {
        "id": "z7vBYOaz7jMK",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dataset_wrapper(session, dataset):\n",
        "    \"\"\"\n",
        "    Wraps TensorFlow dataset into generator.\n",
        "    :param session:\n",
        "    :param dataset: tf.data.Dataset object\n",
        "    \"\"\"\n",
        "    iterator = dataset.make_one_shot_iterator()\n",
        "    next_element = iterator.get_next()\n",
        "    while True:\n",
        "        try:\n",
        "            data = session.run(next_element)\n",
        "            yield data\n",
        "        except tf.errors.OutOfRangeError:\n",
        "            break\n",
        "            \n",
        "def _decode_record(record):\n",
        "    \"\"\"\n",
        "    Decodes record from bytes to arrays.\n",
        "    \"\"\"\n",
        "    features_dict = {\n",
        "        'image': tf.FixedLenFeature((), tf.string),\n",
        "        'tags': tf.FixedLenFeature((), tf.string),\n",
        "    }\n",
        "\n",
        "    features = tf.parse_single_example(record, features=features_dict)\n",
        "    #data had been written as uint8 to save up space...\n",
        "    image = tf.decode_raw(features['image'], tf.uint8)\n",
        "    image = tf.reshape(image, shape=(218, 178, 3))\n",
        "    #.. but we need more precison on calculation\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = image / 255.0 #normalize\n",
        "    tags = tf.decode_raw(features['tags'], tf.uint8)\n",
        "\n",
        "    return {\n",
        "        'image': image,\n",
        "        'tags': tags\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F-lGw92675t6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_dataset(dataset_path, batch_size=128, shuffle=False, epochs=1, count_limit=None):\n",
        "    \"\"\"\n",
        "    Creates dataset pipeline.\n",
        "    :param count_limit:\n",
        "    :return: tf.data.TFRecordDataset object\n",
        "    \"\"\"\n",
        "    # Read a tf record file. This makes a dataset of raw TFRecords\n",
        "    dataset = tf.data.TFRecordDataset([dataset_path])\n",
        "\n",
        "    if count_limit is not None:\n",
        "        dataset = dataset.take(count_limit)\n",
        "\n",
        "    # Can be parallelized!\n",
        "    dataset = dataset.map(_decode_record, num_parallel_calls=DECODE_PARALLEL_CALLS)\n",
        "\n",
        "    dataset = dataset.repeat(epochs)\n",
        "\n",
        "    if shuffle:\n",
        "        # Shuffle the dataset\n",
        "        dataset = dataset.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n",
        "\n",
        "    # Batch the dataset so that we get batch_size examples in each batch.\n",
        "    # Remember each item in the dataset is a dict of tensors,\n",
        "    # we need to specify padding for each tensor seperatly\n",
        "    dataset = dataset.batch(batch_size)\n",
        "\n",
        "    # Async loading, must-have!\n",
        "    dataset = dataset.prefetch(buffer_size=PREFETCH_BUFFER_SIZE)\n",
        "\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s4VU1E-b1Iwc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Writting to TFRecords"
      ]
    },
    {
      "metadata": {
        "id": "KTj0jMibE8Kg",
        "colab_type": "code",
        "outputId": "54031056-b0e3-4de9-9397-6eb1faee0999",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "cell_type": "code",
      "source": [
        "peek_file(EVAL_PATH, 20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "000001.jpg 0\n",
            "000002.jpg 0\n",
            "000003.jpg 0\n",
            "000004.jpg 0\n",
            "000005.jpg 0\n",
            "000006.jpg 0\n",
            "000007.jpg 0\n",
            "000008.jpg 0\n",
            "000009.jpg 0\n",
            "000010.jpg 0\n",
            "000011.jpg 0\n",
            "000012.jpg 0\n",
            "000013.jpg 0\n",
            "000014.jpg 0\n",
            "000015.jpg 0\n",
            "000016.jpg 0\n",
            "000017.jpg 0\n",
            "000018.jpg 0\n",
            "000019.jpg 0\n",
            "000020.jpg 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Cf1hLkunFTWt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _load_splits():\n",
        "    \"\"\"\n",
        "    Load split for train/val/test dataset.\n",
        "    To be implemented by students.\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    splits = defaultdict(lambda: list())\n",
        "\n",
        "    with open(EVAL_PATH, mode='rt', encoding='utf-8') as file_:\n",
        "        for line in file_:\n",
        "            file_name, class_value = line.strip().split(' ')\n",
        "            assert(class_value in ['0', '1', '2'])\n",
        "            splits[class_value].append(file_name)\n",
        "\n",
        "    return dict(splits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4b8JV19lFM2M",
        "colab_type": "code",
        "outputId": "972e169b-9f4d-4ecb-e104-ae11aa81efc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "cell_type": "code",
      "source": [
        "peek_file(ANNO_PATH, 20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "202599\n",
            "5_o_Clock_Shadow Arched_Eyebrows Attractive Bags_Under_Eyes Bald Bangs Big_Lips Big_Nose Black_Hair Blond_Hair Blurry Brown_Hair Bushy_Eyebrows Chubby Double_Chin Eyeglasses Goatee Gray_Hair Heavy_Makeup High_Cheekbones Male Mouth_Slightly_Open Mustache Narrow_Eyes No_Beard Oval_Face Pale_Skin Pointy_Nose Receding_Hairline Rosy_Cheeks Sideburns Smiling Straight_Hair Wavy_Hair Wearing_Earrings Wearing_Hat Wearing_Lipstick Wearing_Necklace Wearing_Necktie Young \n",
            "000001.jpg -1  1  1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1  1  1 -1  1 -1 -1  1 -1 -1  1 -1 -1 -1  1  1 -1  1 -1  1 -1 -1  1\n",
            "000002.jpg -1 -1 -1  1 -1 -1 -1  1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1  1 -1  1 -1 -1  1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1  1\n",
            "000003.jpg -1 -1 -1 -1 -1 -1  1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1  1  1 -1 -1  1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1  1\n",
            "000004.jpg -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1  1 -1 -1 -1 -1  1 -1  1 -1  1  1 -1  1\n",
            "000005.jpg -1  1  1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1  1  1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1  1\n",
            "000006.jpg -1  1  1 -1 -1 -1  1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1  1 -1 -1  1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1  1  1 -1  1 -1 -1  1\n",
            "000007.jpg 1 -1  1  1 -1 -1  1  1  1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1  1 -1 -1  1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1  1\n",
            "000008.jpg 1  1 -1  1 -1 -1  1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1  1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1\n",
            "000009.jpg -1  1  1 -1 -1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1 -1  1 -1 -1  1  1 -1  1 -1  1 -1  1 -1 -1  1 -1  1 -1 -1  1\n",
            "000010.jpg -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1  1 -1 -1  1\n",
            "000011.jpg -1 -1  1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1  1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1  1\n",
            "000012.jpg -1 -1  1  1 -1 -1 -1 -1  1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1  1  1  1 -1 -1  1  1 -1 -1 -1 -1 -1  1  1 -1 -1 -1 -1 -1 -1  1\n",
            "000013.jpg -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1  1 -1 -1  1  1 -1 -1 -1 -1 -1  1  1 -1 -1 -1 -1 -1 -1  1\n",
            "000014.jpg -1  1 -1 -1 -1 -1 -1  1  1 -1 -1 -1  1 -1 -1 -1 -1 -1  1  1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1  1  1 -1  1\n",
            "000015.jpg 1 -1 -1  1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1  1  1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1  1 -1\n",
            "000016.jpg 1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1 -1 -1 -1 -1 -1 -1  1\n",
            "000017.jpg -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1  1 -1 -1  1  1 -1 -1 -1 -1 -1  1  1 -1 -1 -1 -1 -1 -1  1\n",
            "000018.jpg -1  1 -1 -1 -1 -1 -1  1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1  1  1 -1  1 -1  1  1 -1 -1  1 -1  1 -1  1 -1  1  1 -1  1  1 -1 -1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ugqH806c1wS_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _load_tags():\n",
        "    \"\"\"\n",
        "    Load tags (classes) for images.\n",
        "    To be implemented by students.\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    tags_result = dict()\n",
        "    with open(ANNO_PATH, mode='rt', encoding='utf-8') as file_:\n",
        "        next(file_)\n",
        "        tag_names = [tag.lower() for tag in next(file_).strip().split(' ')]\n",
        "        for line in file_:\n",
        "            parsed_line = line.strip().replace('  ', ' ').split(' ')\n",
        "            file_name = parsed_line[0]\n",
        "            tags = np.array([int(tag) for tag in parsed_line[1:]])\n",
        "            tags = tags > 0.5\n",
        "            tags = tags.astype(np.uint8)\n",
        "            tags_result[file_name] = tags\n",
        "\n",
        "    return tags_result, tag_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QbGi50hx2B-u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _bytes_feature(value):\n",
        "    \"\"\"\n",
        "    Helper function for feature encoding.\n",
        "    :param value:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
        "\n",
        "def _write_records(dataset_filename, image_filename_iterator, tags):\n",
        "    \"\"\"\n",
        "    Writes images and tags to file.\n",
        "    :param dataset_filename:\n",
        "    :param image_filename_iterator: iterable containing filenames\n",
        "    :param tags: dictionary containing pairs filename: tags\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    with tf.python_io.TFRecordWriter(dataset_filename) as writer:\n",
        "        for image_filename in tqdm(iterable=image_filename_iterator,\n",
        "                                   desc='writting {} dataset'.format(dataset_filename)):\n",
        "            tag = tags[image_filename]\n",
        "            image = misc.imread(os.path.join(IMG_PATH, image_filename.replace('.jpg', '.png')))\n",
        "\n",
        "            # store as uint8\n",
        "            image = image.astype(np.uint8)\n",
        "            feature = {\n",
        "                'image': _bytes_feature([image.tostring()]),\n",
        "                'tags': _bytes_feature([tag.tostring()]),\n",
        "            }\n",
        "            example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "            writer.write(example.SerializeToString())\n",
        "    sys.stdout.flush()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PQKAPnsX1Tis",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _create_dataset(train_filename, val_filename, test_filename):\n",
        "    \"\"\"\n",
        "    Creates dataset in target location.\n",
        "    To be implemented by students\n",
        "    :param train_filename:\n",
        "    :param val_filename:\n",
        "    :param test_filename:\n",
        "    \"\"\"\n",
        "    splits = _load_splits()\n",
        "    tags, _ = _load_tags()\n",
        "\n",
        "    _write_records(train_filename, splits['0'], tags)\n",
        "    _write_records(val_filename, splits['1'], tags)\n",
        "    _write_records(test_filename, splits['2'], tags)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4goFOy2c1ISl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def maybe_create_dataset():\n",
        "    \"\"\"\n",
        "    Function creates TensorFlow dataset if it does not exist.\n",
        "    :return: (train_filename, val_filename, test_filename)\n",
        "    \"\"\"\n",
        "    train_filename = os.path.join(SAVED_DATASET, TRAIN_FILENAME)\n",
        "    val_filename = os.path.join(SAVED_DATASET, VAL_FILENAME)\n",
        "    test_filename = os.path.join(SAVED_DATASET, TEST_FILENAME)\n",
        "\n",
        "    if not all([os.path.exists(filename)\n",
        "                for filename\n",
        "                in [train_filename, val_filename, test_filename]]):\n",
        "        _create_dataset(train_filename, val_filename, test_filename)\n",
        "    return train_filename, val_filename, test_filename"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bJiqs9Hl3-JV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Model"
      ]
    },
    {
      "metadata": {
        "id": "vBRODazp7Zcz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "    def report_parameters(scope=None):\n",
        "        \"\"\"\n",
        "        Reports names, shape and number of parameters.\n",
        "        :param scope: string, scope to report, defaults to global values\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        denses = 0\n",
        "        other = 0\n",
        "        print('Summary')\n",
        "        for parameter_tensor in tf.trainable_variables(scope=scope):\n",
        "            total = np.prod(parameter_tensor.shape).value\n",
        "            print('Name: {}, Shape: {}, Total: {}'.format(\n",
        "                parameter_tensor.name, parameter_tensor.shape, total))\n",
        "\n",
        "            if 'dense' in parameter_tensor.name:\n",
        "                denses += total\n",
        "            else:\n",
        "                other += total\n",
        "\n",
        "        print('')\n",
        "        print('Feature Extractor: {} -> {:.2f}%'.format(other, 100*other/(other+denses)))\n",
        "        print('Predictor: {} -> {:.2f}%'.format(denses, 100*denses/(other+denses)))\n",
        "        print('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0eSzjg8s7rm_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_class_weights():\n",
        "  \n",
        "  \n",
        "    \"\"\"\n",
        "    Creates weights for classes based on training set.\n",
        "    :return: numpy array [num_classes,]\n",
        "    \"\"\"\n",
        "    tags, _ = _load_tags()\n",
        "    splits = _load_splits()\n",
        "\n",
        "    weights = np.array([tags[name] for name in splits['0']])\n",
        "    weights = weights.mean(axis=0)\n",
        "    weights = 1.0 / weights\n",
        "\n",
        "    return weights\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JQ4AqRpH38tC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class AlexNet:\n",
        "    def __init__(self, input_shape, num_outputs, class_weights=None, create_loss=True, create_metrics=True):\n",
        "        \"\"\"\n",
        "        Constructor for AlexNet, creates model, loss and metrics based on input and output shapes.\n",
        "        :param input_shape: tuple, (width, height, channels)\n",
        "        :param num_outputs: integer, number of classes in prediction\n",
        "        :param class_weights: array, containing weights for positive classes, length equals to num_outputs\n",
        "        :param create_loss: bool, indicates if loss should be created\n",
        "        :param create_metrics: bool, idicates if tensorboard metrics should be created\n",
        "        \"\"\"\n",
        "        self._input_shape = list(input_shape)\n",
        "        self._num_outputs = num_outputs\n",
        "        self._class_weights = class_weights\n",
        "\n",
        "        with tf.variable_scope('alex_net'):\n",
        "            self.p_image, self.p_tags, self.p_training = self._create_placeholders()\n",
        "            self.o_tags = self._create_model()\n",
        "            if create_loss:\n",
        "                self.o_loss = self._create_loss()\n",
        "            else:\n",
        "                self.o_loss = tf.no_op()\n",
        "\n",
        "            if create_metrics:\n",
        "                self._create_metrics()\n",
        "\n",
        "\n",
        "\n",
        "    def _create_placeholders(self):\n",
        "        \"\"\"\n",
        "        Function creates placeholders for data. After running, 3 placeholders should be created:\n",
        "        p_image for images, p_tags for expected outputs, p_training to indicate training phase.\n",
        "        :return: (p_image, p_tags, p_training)\n",
        "        \"\"\"\n",
        "        with tf.variable_scope('placeholders'):\n",
        "            p_image = tf.placeholder(\n",
        "                dtype=tf.float32,\n",
        "                shape=[None] + self._input_shape,\n",
        "                name='p_image'\n",
        "            )\n",
        "\n",
        "            p_tags = tf.placeholder(\n",
        "                dtype=tf.float32,\n",
        "                shape=[None, self._num_outputs],\n",
        "                name='p_tags'\n",
        "            )\n",
        "\n",
        "            p_training = tf.placeholder(\n",
        "                dtype=tf.bool,\n",
        "                shape=(),\n",
        "                name='p_training',\n",
        "            )\n",
        "\n",
        "        return p_image, p_tags, p_training\n",
        "\n",
        "\n",
        "    def _augment(self, images):\n",
        "        \"\"\"\n",
        "        Function randomly augments images during training.\n",
        "        :param images: tensor (batch, width, height, channels), contains images in current batch\n",
        "        :return: augmented images with the same shape as input\n",
        "        \"\"\"\n",
        "        images = tf.image.random_flip_left_right(images)\n",
        "        images = tf.image.random_hue(images, 0.01)\n",
        "        images = tf.image.random_saturation(images, 0.2, 1.8)\n",
        "        images = tf.image.random_brightness(images, 0.2)\n",
        "        images = tf.minimum(images, 1.0)\n",
        "        images = tf.maximum(images, 0.0)\n",
        "        return images\n",
        "\n",
        "    def _create_model(self):\n",
        "       \n",
        "      \n",
        "      \n",
        "        \"\"\"\n",
        "        Function that creates model based on placeholders in self.\n",
        "        :return: tensor, logits for outputs (batch, num_outputs)\n",
        "        \"\"\"\n",
        "        with tf.variable_scope('augmentation'):\n",
        "            layer_input = tf.cond(\n",
        "                self.p_training,\n",
        "                true_fn=lambda: self._augment(self.p_image),\n",
        "                false_fn=lambda: tf.identity(self.p_image),\n",
        "            )\n",
        "\n",
        "        with tf.variable_scope('conv1'):\n",
        "            layer_input = tf.layers.conv2d(\n",
        "                inputs=layer_input,\n",
        "                filters=96,\n",
        "                kernel_size=(11, 11),\n",
        "                strides=(4, 4),\n",
        "                padding='VALID',\n",
        "                use_bias=True,\n",
        "            )\n",
        "            layer_input = tf.nn.relu(layer_input)\n",
        "\n",
        "        with tf.variable_scope('norm1'):\n",
        "            layer_input = tf.nn.local_response_normalization(\n",
        "                input=layer_input,\n",
        "                depth_radius=2,\n",
        "                alpha=1e-05,\n",
        "                beta=0.75,\n",
        "                bias=1.0,\n",
        "            )\n",
        "\n",
        "        with tf.variable_scope('pool1'):\n",
        "            layer_input = tf.layers.max_pooling2d(\n",
        "                inputs=layer_input,\n",
        "                pool_size=(3, 3),\n",
        "                strides=(2, 2),\n",
        "                padding='VALID',\n",
        "            )\n",
        "\n",
        "        with tf.variable_scope('conv2'):\n",
        "            layer_input = tf.layers.conv2d(\n",
        "                inputs=layer_input,\n",
        "                filters=256,\n",
        "                kernel_size=(5, 5),\n",
        "                strides=(1, 1),\n",
        "                padding='SAME',\n",
        "                use_bias=True,\n",
        "            )\n",
        "            layer_input = tf.nn.relu(layer_input)\n",
        "\n",
        "        with tf.variable_scope('norm2'):\n",
        "            layer_input = tf.nn.local_response_normalization(\n",
        "                input=layer_input,\n",
        "                depth_radius=2,\n",
        "                alpha=1e-05,\n",
        "                beta=0.75,\n",
        "                bias=1.0,\n",
        "            )\n",
        "\n",
        "        with tf.variable_scope('pool2'):\n",
        "            layer_input = tf.layers.max_pooling2d(\n",
        "                inputs=layer_input,\n",
        "                pool_size=(3, 3),\n",
        "                strides=(2, 2),\n",
        "                padding='VALID',\n",
        "            )\n",
        "\n",
        "        with tf.variable_scope('conv3'):\n",
        "            layer_input = tf.layers.conv2d(\n",
        "                inputs=layer_input,\n",
        "                filters=384,\n",
        "                kernel_size=(3, 3),\n",
        "                strides=(1, 1),\n",
        "                padding='SAME',\n",
        "                use_bias=True,\n",
        "            )\n",
        "            layer_input = tf.nn.relu(layer_input)\n",
        "\n",
        "        with tf.variable_scope('conv4'):\n",
        "            layer_input = tf.layers.conv2d(\n",
        "                inputs=layer_input,\n",
        "                filters=384,\n",
        "                kernel_size=(3, 3),\n",
        "                strides=(1, 1),\n",
        "                padding='SAME',\n",
        "                use_bias=True,\n",
        "            )\n",
        "            layer_input = tf.nn.relu(layer_input)\n",
        "\n",
        "        with tf.variable_scope('conv5'):\n",
        "            layer_input = tf.layers.conv2d(\n",
        "                inputs=layer_input,\n",
        "                filters=256,\n",
        "                kernel_size=(3, 3),\n",
        "                strides=(1, 1),\n",
        "                padding='SAME',\n",
        "                use_bias=True,\n",
        "            )\n",
        "            layer_input = tf.nn.relu(layer_input)\n",
        "\n",
        "        with tf.variable_scope('pool5'):\n",
        "            layer_input = tf.layers.max_pooling2d(\n",
        "                inputs=layer_input,\n",
        "                pool_size=(3, 3),\n",
        "                strides=(2, 2),\n",
        "                padding='VALID',\n",
        "            )\n",
        "\n",
        "        with tf.variable_scope('flatten'):\n",
        "            layer_input = tf.reshape(\n",
        "                tensor=layer_input,\n",
        "                shape=[-1, np.prod(layer_input.shape[1:])],\n",
        "            )\n",
        "\n",
        "        with tf.variable_scope('fc6'):\n",
        "            layer_input = tf.layers.dense(\n",
        "                inputs=layer_input,\n",
        "                units=1*1024,\n",
        "                use_bias=True,\n",
        "            )\n",
        "            layer_input = tf.nn.relu(layer_input)\n",
        "\n",
        "        with tf.variable_scope('dropout6'):\n",
        "            layer_input = tf.layers.dropout(\n",
        "                inputs=layer_input,\n",
        "                rate=0.5,\n",
        "                training=self.p_training,\n",
        "            )\n",
        "\n",
        "        with tf.variable_scope('fc7'):\n",
        "            layer_input = tf.layers.dense(\n",
        "                inputs=layer_input,\n",
        "                units=1*1024,\n",
        "                use_bias=True,\n",
        "            )\n",
        "            layer_input = tf.nn.relu(layer_input)\n",
        "\n",
        "        with tf.variable_scope('dropout7'):\n",
        "            layer_input = tf.layers.dropout(\n",
        "                inputs=layer_input,\n",
        "                rate=0.5,\n",
        "                training=self.p_training,\n",
        "            )\n",
        "\n",
        "        with tf.variable_scope('fc8'):\n",
        "            layer_input = tf.layers.dense(\n",
        "                inputs=layer_input,\n",
        "                units=self._num_outputs,\n",
        "                use_bias=True,\n",
        "            )\n",
        "\n",
        "        return layer_input\n",
        "\n",
        "    def _create_loss(self):\n",
        "        \n",
        "      \n",
        "        \"\"\"\n",
        "        Adds cross-entropy loss function to the graph. If self.class_weights \n",
        "        is not None, cross-entropy is wieghted by self.class_weights\n",
        "        :return: reference to loss function operation\n",
        "        \"\"\"\n",
        "        \n",
        "        with tf.variable_scope('loss'):\n",
        "            if self._class_weights is not None:\n",
        "                o_loss = tf.nn.weighted_cross_entropy_with_logits(\n",
        "                    targets=self.p_tags,\n",
        "                    logits=self.o_tags,\n",
        "                    pos_weight=self._class_weights,\n",
        "                )\n",
        "            else:\n",
        "                o_loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "                    labels=self.p_tags,\n",
        "                    logits=self.o_tags,\n",
        "                )\n",
        "                \n",
        "        return tf.reduce_mean(o_loss)\n",
        "\n",
        "    def _create_metrics(self):\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O3cQ4qYBqAeI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Metrics"
      ]
    },
    {
      "metadata": {
        "id": "uTB1hoSspwTN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def calculate_per_class_fscore(y_true, y_pred):\n",
        "  \n",
        "    \"\"\"\n",
        "    Calculates per class fscore. Applied every epoch.\n",
        "    :param y_true: np.array of ground truth (binary). Shape: (examples in dataset, labels)\n",
        "    :param y_pred: np.array of prediction per class (binary). Shape: (examples in dataset, labels)\n",
        "    :return: np.array of f1 score per class. Shape: (labels, ) \n",
        "    \"\"\"\n",
        "    return [f1_score(y_true[:, num_class], y_pred[:, num_class])\n",
        "            for num_class in range(y_true.shape[1])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NlCSDMylzd7d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Main pipeline"
      ]
    },
    {
      "metadata": {
        "id": "HWC-26Di0rRU",
        "colab_type": "code",
        "outputId": "6cad20c1-8aa3-41ad-c75d-828144268092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "cell_type": "code",
      "source": [
        "train_filename, val_filename, test_filename = maybe_create_dataset()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "writting /content/preprocessed/train.tfrecords dataset:   0%|          | 0/162770 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imread`` instead.\n",
            "writting /content/preprocessed/train.tfrecords dataset: 100%|██████████| 162770/162770 [13:37<00:00, 199.10it/s]\n",
            "writting /content/preprocessed/val.tfrecords dataset: 100%|██████████| 19867/19867 [01:41<00:00, 195.24it/s]\n",
            "writting /content/preprocessed/test.tfrecords dataset: 100%|██████████| 19962/19962 [01:41<00:00, 196.79it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "SkAWsDWRpdwM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "with tf.variable_scope('faces'):\n",
        "    \n",
        "    faces_net = AlexNet((218, 178, 3), 40, create_loss=True, create_metrics=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RC0Ni8Hm3T6W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def epoch_loop(session, model, dataset, training_op=None):\n",
        "    \"\"\"\n",
        "    Basic train/test loop. Runs model on given dataset.\n",
        "    :param session: session to the graph \n",
        "    :param model: AlexNet object\n",
        "    :param dataset: dataset to train/validate on\n",
        "    :param training_op: minimize operation if training, None if validating/testing\n",
        "    :return: (total_loss, per_class_fscores)\n",
        "    \"\"\"\n",
        "    do_train = training_op is not None # pass this to a placeholder\n",
        "    training_op = tf.no_op() if training_op is None else training_op\n",
        "    \n",
        "    #TASK 3\n",
        "\n",
        "    total_loss = list() # list of loss function after each batch\n",
        "    tags_pred = list() #list of predicted tags\n",
        "    tags_true = list() # list of ground truth\n",
        "    per_class_fscores = list()\n",
        "    \n",
        "    iterator = dataset.make_initializable_iterator()\n",
        "    session.run(iterator.initializer)\n",
        "\n",
        "    next_batch = iterator.get_next()\n",
        "\n",
        "    session.run(tf.global_variables_initializer())\n",
        "\n",
        "    \n",
        "    for data in tqdm(dataset_wrapper(session, dataset)):\n",
        "      result = session.run(model.o_tags, feed_dict={model.p_image: data['image'],\n",
        "                  model.p_tags: data['tags'],\n",
        "                  model.p_training: True,})\n",
        "      print(tf.math.sigmoid(result).eval())\n",
        "      break;\n",
        "\n",
        "    return total_loss, per_class_fscores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X3QB2JY22NbA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_training(model, train_filename, val_filename, learning_rate):\n",
        "    \"\"\"\n",
        "    Performs complete training.\n",
        "    :param model:properly build and adapted AlexNet for CelebFaces dataset\n",
        "    :param train_filename: path to train TFRecords file\n",
        "    :param val_filename: path to validation TFRecord file\n",
        "    :param test_filename: path to test TFRecord file\n",
        "    :param run:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "#     with tf.variable_scope('optimization'):\n",
        "\n",
        "        # TASK 1 - Add optimizer on loss function\n",
        "        # DONE 18.12.2018 20:04\n",
        "#         training_op = tf.train.AdamOptimizer(learning_rate).minimize(model._create_loss())\n",
        "        #init_op = tf.initialize_all_variables()\n",
        "        \n",
        "        \n",
        "    with tf.Session() as session:\n",
        "      \n",
        "        training_op = tf.train.AdamOptimizer(learning_rate).minimize(model._create_loss())\n",
        "        # TASK 2 - initialize variables of the model; for every epoch, create 2 datasets: train and validation\n",
        "        # using make_dataset function\n",
        "        \n",
        "        #epoch_loop(session, model, dataset, training_op=None)\n",
        "        #make_dataset(dataset_path, batch_size=128, shuffle=False, epochs=1, count_limit=None)\n",
        "        for epoch in range(EPOCHS):\n",
        "       \n",
        "            train_dataset = make_dataset(train_filename, batch_size=128, shuffle=True, epochs=1, count_limit=10)\n",
        "            validation_dataset = make_dataset(val_filename, batch_size=128, shuffle=False, epochs=1, count_limit=10)\n",
        "            \n",
        "            train_loss, train_fscores = epoch_loop(session, model, train_dataset, training_op) # feed it with proper arguments\n",
        "            val_loss, val_fscores = epoch_loop(session, model, validation_dataset) # feed it with proper arguments\n",
        "\n",
        "\n",
        "            print('Train: Loss: {} FScore: {}'.format(train_loss, train_fscores.mean()))\n",
        "            print('Val: Loss: {} FScore: {}'.format(val_loss, val_fscores.mean()))\n",
        "#             print('Test: Loss: {} FScore: {}'.format(test_loss, test_fscores.mean()))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ilUmq-_g996N",
        "colab_type": "code",
        "outputId": "e87c340f-f7dd-47c1-edaa-047af9864bf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2752
        }
      },
      "cell_type": "code",
      "source": [
        "run_training(faces_net, train_filename, val_filename, learning_rate = 0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[0.50808156 0.5026448  0.49377736 0.4971764  0.4770981  0.47324893\n",
            "  0.5073217  0.5029614  0.49981833 0.48253897 0.49307847 0.4988124\n",
            "  0.4934033  0.5069897  0.51285833 0.48443902 0.5025996  0.47642162\n",
            "  0.4831494  0.517575   0.46190384 0.48143837 0.49820426 0.4990758\n",
            "  0.4989071  0.49988332 0.5102258  0.49327007 0.51089865 0.50244665\n",
            "  0.48973373 0.5051826  0.5143566  0.491346   0.49245965 0.5080527\n",
            "  0.49675146 0.4985261  0.4702353  0.50140005]\n",
            " [0.4887118  0.5212405  0.47877914 0.49065885 0.476075   0.5046369\n",
            "  0.5063266  0.48717445 0.49022993 0.4919198  0.50566864 0.5041952\n",
            "  0.50187135 0.51737046 0.4829657  0.49669722 0.50947315 0.4929175\n",
            "  0.49351773 0.50930834 0.48927945 0.48879638 0.48862827 0.49937707\n",
            "  0.50314057 0.51699954 0.5081155  0.4958262  0.5026361  0.47595522\n",
            "  0.49982482 0.5036967  0.50963134 0.50955945 0.4807838  0.5066466\n",
            "  0.49774298 0.4923181  0.49494675 0.50025713]\n",
            " [0.5070104  0.5172233  0.501683   0.50183916 0.48794943 0.5083543\n",
            "  0.5058552  0.5041571  0.51866764 0.5099896  0.4888235  0.49135885\n",
            "  0.50333035 0.5196677  0.48493415 0.48524573 0.49408197 0.48696947\n",
            "  0.4940406  0.5157184  0.4775238  0.50888234 0.4925918  0.47939965\n",
            "  0.49825588 0.5183716  0.5222663  0.5035493  0.51111346 0.49010146\n",
            "  0.516356   0.5028661  0.49530897 0.49329206 0.50955635 0.49908063\n",
            "  0.5175658  0.4790345  0.49841976 0.5084481 ]\n",
            " [0.5072679  0.5055096  0.5099073  0.48036245 0.48301643 0.5035231\n",
            "  0.50748485 0.4890331  0.4897331  0.48046988 0.48338482 0.49573573\n",
            "  0.5123014  0.5058206  0.49732202 0.4979549  0.5006112  0.48287007\n",
            "  0.49899057 0.50241673 0.49606746 0.50112927 0.5054036  0.4949995\n",
            "  0.49112308 0.5010272  0.49208283 0.4982554  0.49489138 0.4784955\n",
            "  0.50864506 0.5039751  0.5111512  0.49373013 0.49853018 0.4906029\n",
            "  0.5117294  0.5067731  0.5098529  0.49773365]\n",
            " [0.49410155 0.5113829  0.49853724 0.4818321  0.4603156  0.48185578\n",
            "  0.52232015 0.4871088  0.48536715 0.51197004 0.4882082  0.50622463\n",
            "  0.5223869  0.5154105  0.49097216 0.47824326 0.4866455  0.49591064\n",
            "  0.5002508  0.53049153 0.49636528 0.4818828  0.512924   0.49471527\n",
            "  0.510918   0.50798315 0.49930894 0.5039991  0.5114556  0.4957506\n",
            "  0.5152273  0.4807538  0.48995936 0.50255907 0.5076741  0.49626997\n",
            "  0.5133223  0.509245   0.4891028  0.5084959 ]\n",
            " [0.50347906 0.50594115 0.5009781  0.47607353 0.48418927 0.4974389\n",
            "  0.49446556 0.48485515 0.4815409  0.49707288 0.4967238  0.5171604\n",
            "  0.5122024  0.5034912  0.4702837  0.48943496 0.49363568 0.47670475\n",
            "  0.4803891  0.49706805 0.47472456 0.498384   0.50551003 0.5041213\n",
            "  0.52284896 0.4918702  0.5119751  0.5177938  0.49665603 0.48324415\n",
            "  0.4967657  0.4948829  0.51592726 0.5093843  0.4822648  0.49992478\n",
            "  0.5152694  0.51328146 0.49838004 0.51376605]\n",
            " [0.5065043  0.49994737 0.483899   0.496241   0.506473   0.48652062\n",
            "  0.49883223 0.48098105 0.49257144 0.50265855 0.49367613 0.51517934\n",
            "  0.49786457 0.49980697 0.4903765  0.48395115 0.5102837  0.48645878\n",
            "  0.4957321  0.52449524 0.49110526 0.48636547 0.4926141  0.4847529\n",
            "  0.50995946 0.5026317  0.5047947  0.5037588  0.5072077  0.497803\n",
            "  0.49911642 0.49234942 0.4990181  0.5288444  0.49567282 0.4988627\n",
            "  0.505771   0.48707056 0.5055247  0.4905672 ]\n",
            " [0.5020026  0.4882302  0.4904132  0.49269435 0.50636506 0.48920766\n",
            "  0.5043631  0.51003736 0.4885849  0.5199735  0.5093808  0.5013582\n",
            "  0.5096046  0.497035   0.51496637 0.4855158  0.48956922 0.4871372\n",
            "  0.49889857 0.51711076 0.47034127 0.4851322  0.48133847 0.48087722\n",
            "  0.5033912  0.5113074  0.50182915 0.4988862  0.5166517  0.49623305\n",
            "  0.51335245 0.5133755  0.51695806 0.5166267  0.5097274  0.50586987\n",
            "  0.52012455 0.50385237 0.48988634 0.50240695]\n",
            " [0.50094384 0.5075664  0.47711006 0.4942332  0.47422254 0.48068967\n",
            "  0.5155142  0.49232283 0.5138155  0.48229825 0.4958692  0.5149895\n",
            "  0.529598   0.5037307  0.48483056 0.4669496  0.50683326 0.47564164\n",
            "  0.46926484 0.5228493  0.4884063  0.4727733  0.48633644 0.46988833\n",
            "  0.50956684 0.5064516  0.5205569  0.5056214  0.50661266 0.5025252\n",
            "  0.5107243  0.53026724 0.48276636 0.49256173 0.5052788  0.48037526\n",
            "  0.49609435 0.4980547  0.51346993 0.47150162]\n",
            " [0.5075985  0.5116632  0.48394713 0.48976701 0.50837314 0.500528\n",
            "  0.4977636  0.5062961  0.49994755 0.48710424 0.49864256 0.49141988\n",
            "  0.51545304 0.5030513  0.4861929  0.4827278  0.51076245 0.47915763\n",
            "  0.49920702 0.5091199  0.4909352  0.49321207 0.4920774  0.49519247\n",
            "  0.5148591  0.493546   0.5075786  0.5169746  0.5058763  0.49362105\n",
            "  0.5185378  0.5050782  0.49291456 0.5150222  0.4814801  0.5053802\n",
            "  0.511035   0.5011584  0.4953196  0.50155586]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[0.48041797 0.49777666 0.50768864 0.51756203 0.5014831  0.49969488\n",
            "  0.49314305 0.4864622  0.4926691  0.5147382  0.50645053 0.488077\n",
            "  0.50730723 0.50333077 0.50134546 0.5014474  0.4679657  0.48614928\n",
            "  0.4951597  0.50398046 0.5036476  0.4733189  0.5027347  0.520713\n",
            "  0.496088   0.51536113 0.49741197 0.49893773 0.50636894 0.5016812\n",
            "  0.49556258 0.50043106 0.4876575  0.49063542 0.48522952 0.4982153\n",
            "  0.48631123 0.4978211  0.5073012  0.49145856]\n",
            " [0.5048896  0.5129661  0.50020593 0.5043577  0.49582517 0.50857913\n",
            "  0.49413002 0.463412   0.49381375 0.48630852 0.5073737  0.5142969\n",
            "  0.50656766 0.5113311  0.520004   0.48548192 0.50483197 0.4834439\n",
            "  0.49830425 0.5044077  0.5075693  0.48100036 0.4941058  0.51333535\n",
            "  0.503854   0.5031838  0.49679363 0.5069006  0.50782716 0.49504894\n",
            "  0.50361    0.5089896  0.5091132  0.48508996 0.5003667  0.4831671\n",
            "  0.47158778 0.4671948  0.5052024  0.5020227 ]\n",
            " [0.5021665  0.5097747  0.49573362 0.5010353  0.49840283 0.48977515\n",
            "  0.49029383 0.4883808  0.50913155 0.50945944 0.5058739  0.50874686\n",
            "  0.5135153  0.5027604  0.511069   0.4945552  0.49239537 0.4866077\n",
            "  0.50167704 0.5003177  0.5022603  0.49291512 0.5102285  0.5129479\n",
            "  0.5037084  0.5148726  0.4869616  0.50145805 0.5021252  0.50370634\n",
            "  0.49557495 0.5017302  0.49055368 0.4911263  0.49789932 0.48178476\n",
            "  0.4816016  0.4954399  0.49447492 0.48631337]\n",
            " [0.49211523 0.4928429  0.5010311  0.5147887  0.50836235 0.4952023\n",
            "  0.485405   0.50150436 0.4943343  0.49567315 0.50580025 0.49744463\n",
            "  0.5086071  0.5025724  0.4983461  0.48483497 0.50143206 0.4919623\n",
            "  0.498377   0.5023638  0.49944034 0.49872842 0.50738204 0.5081989\n",
            "  0.5015974  0.50613457 0.50310934 0.49500698 0.5075199  0.50261843\n",
            "  0.50369203 0.49958444 0.49940813 0.49032342 0.49565476 0.4935482\n",
            "  0.4788225  0.48935896 0.4952976  0.495173  ]\n",
            " [0.48584434 0.49535903 0.5150408  0.5115945  0.48562586 0.49880558\n",
            "  0.49978694 0.49851936 0.5008874  0.5017475  0.5180948  0.4787392\n",
            "  0.5009353  0.5201435  0.50717384 0.46962416 0.49373803 0.4903889\n",
            "  0.50705683 0.49165955 0.51057976 0.47154465 0.5058758  0.51479304\n",
            "  0.511708   0.5060546  0.5001911  0.51723045 0.5106781  0.5106322\n",
            "  0.5084722  0.49398777 0.49449947 0.4894193  0.501939   0.51375437\n",
            "  0.5063347  0.48729116 0.49938473 0.49916965]\n",
            " [0.49299976 0.49661052 0.50990945 0.5041061  0.50208896 0.49689046\n",
            "  0.5099127  0.4962473  0.5038048  0.50093764 0.5107744  0.5013203\n",
            "  0.5002323  0.51580095 0.5082793  0.47460943 0.48799622 0.49025035\n",
            "  0.51691276 0.5180102  0.5185375  0.46886066 0.5015335  0.50039583\n",
            "  0.5102641  0.49433872 0.50638914 0.51341647 0.5036275  0.49830833\n",
            "  0.50373036 0.4936683  0.48573577 0.48224953 0.49196297 0.4852829\n",
            "  0.48831603 0.5182363  0.49890876 0.48308396]\n",
            " [0.499749   0.4954819  0.50537175 0.49776486 0.4910434  0.4914747\n",
            "  0.504264   0.49963692 0.4932613  0.5039591  0.5253346  0.5017661\n",
            "  0.50035036 0.5110087  0.49769738 0.4977921  0.49219954 0.49698272\n",
            "  0.50215006 0.50254244 0.5027654  0.48206624 0.5043756  0.49410927\n",
            "  0.5195958  0.5108835  0.49562198 0.5103721  0.5073655  0.5031188\n",
            "  0.5038264  0.49882236 0.49885702 0.4806627  0.49702594 0.4937719\n",
            "  0.5009011  0.48320594 0.5091967  0.507552  ]\n",
            " [0.5051054  0.49459663 0.50111383 0.49934253 0.5049346  0.49157497\n",
            "  0.4923322  0.49364883 0.49296004 0.50422466 0.50020677 0.51621544\n",
            "  0.5091449  0.5019243  0.51890063 0.4912809  0.4977423  0.49166816\n",
            "  0.49295527 0.50742525 0.5123139  0.49536115 0.49751362 0.50632215\n",
            "  0.4977607  0.5060977  0.5068645  0.5093215  0.5032626  0.49840873\n",
            "  0.50279576 0.5014587  0.50247866 0.50340617 0.5044012  0.50369674\n",
            "  0.49098757 0.4942601  0.4939459  0.49594685]\n",
            " [0.4928151  0.49076092 0.50874925 0.51265055 0.495542   0.5041914\n",
            "  0.49653363 0.48737052 0.49155164 0.5105391  0.5115139  0.48217064\n",
            "  0.5105082  0.5100186  0.517645   0.48678607 0.48098978 0.47416058\n",
            "  0.4992425  0.51157224 0.52046025 0.4772876  0.4884906  0.5059923\n",
            "  0.47870526 0.49370936 0.51286936 0.49406704 0.51653606 0.50767684\n",
            "  0.4961388  0.50155324 0.4921429  0.4929862  0.49091098 0.4939039\n",
            "  0.49953604 0.5034028  0.48603892 0.5010328 ]\n",
            " [0.5055735  0.5061078  0.50735694 0.50953925 0.48969623 0.49451113\n",
            "  0.48190296 0.48569268 0.48568088 0.49477714 0.5126979  0.50132924\n",
            "  0.4994551  0.50321203 0.51487654 0.5012119  0.4856826  0.4868673\n",
            "  0.49372494 0.51018786 0.50141656 0.48788604 0.50216275 0.51183176\n",
            "  0.49980488 0.5066345  0.50251716 0.50900334 0.5139848  0.49597302\n",
            "  0.4888774  0.49112198 0.49852315 0.4899829  0.5117419  0.479859\n",
            "  0.49944243 0.48334828 0.4967915  0.49467036]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-77c7e72b2bf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-79-ffe3d0e0b922>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(model, train_filename, val_filename, learning_rate)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train: Loss: {} FScore: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_fscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Val: Loss: {} FScore: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_fscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m#             print('Test: Loss: {} FScore: {}'.format(test_loss, test_fscores.mean()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'mean'"
          ]
        }
      ]
    }
  ]
}